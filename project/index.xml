<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on cedi.dev</title><link>/project/</link><description>Recent content in Projects on cedi.dev</description><generator>Source Themes academia (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Copyright &amp;copy; {year} by Cedric Kienzler</copyright><lastBuildDate>Mon, 01 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="/project/index.xml" rel="self" type="application/rss+xml"/><item><title>kkpctl</title><link>/project/kkpctl/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>/project/kkpctl/</guid><description>&lt;p>KKPCTL is a command line tool written in early 2021 which implements parts of the Kubermatic Kubernetes Platform (KKP) API and lets you access the API via your command line. The way to use it is similar to tools like kubectl. It’s an open source project hosted on &lt;a href="https://github.com/cedi/kkpctl">GitHub&lt;/a>.&lt;/p></description></item><item><title>KubeOne</title><link>/project/kubeone/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>/project/kubeone/</guid><description>&lt;p>&lt;a href="https://www.kubermatic.com">Kubermatic&lt;/a> &lt;a href="https://github.com/kubermatic/kubeone">KubeOne&lt;/a> automates cluster operations on all your cloud, on-prem, edge, and IoT environments. KubeOne can install high-available (HA) master clusters as well single master clusters.&lt;/p>
&lt;p>All user documentation for the latest stable version is available at the &lt;a href="https://docs.kubermatic.com/kubeone/master/">KubeOne docs website&lt;/a>.&lt;/p></description></item><item><title>Kubermatic Kubernetes Platform</title><link>/project/kkp/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>/project/kkp/</guid><description>&lt;p>&lt;a href="https://www.kubermatic.com">Kubermatic&lt;/a> Kubernetes Platform] is in an &lt;a href="https://github.com/kubermatic/kubermatic">Kubermatic Kubernetes Platform&lt;/a> to centrally manage the global automation of thousands of Kubernetes clusters across multicloud, on-prem and edge with unparalleled density and resilience.&lt;/p>
&lt;p>All user documentation is available at the &lt;a href="https://docs.kubermatic.com/kubermatic/master/">Kubermatic Kubernetes Platform docs website&lt;/a>.&lt;/p></description></item><item><title>Open Infrastructure</title><link>/project/open-infrastructure/</link><pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate><guid>/project/open-infrastructure/</guid><description>&lt;p>&lt;a href="https://open-infrastructure.de">Open-Infrastructure&lt;/a>&lt;/p>
&lt;p>Infrastructure should be accessible for everyone.
except racists, homophobes, sexists, other scum.&lt;/p></description></item><item><title>BIO Routing</title><link>/project/bio-routing/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>/project/bio-routing/</guid><description>&lt;p>A &lt;a href="https://github.com/bio-routing/bio-rd">open-source re-implementation&lt;/a> of BGP, IS-IS and OSPF in go. We value respect and robustness!&lt;/p></description></item><item><title>Chaos Communication Congress Orga</title><link>/project/congress/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>/project/congress/</guid><description>&lt;p>As part of the &lt;a href="https://twitter.com/c3logistic">C3LOC&lt;/a> and the &lt;a href="http://twitter.com/c3bar">C3Bar&lt;/a> teams I helped organizing the logisticts, enabling other cruical teams of the congress orga to make the event happen. As part of the bar team, I helped the 14.000 attendees of the event staying hydrated during the day and drunk during the night.&lt;/p></description></item><item><title>GPN NOC</title><link>/project/gpn/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>/project/gpn/</guid><description>&lt;p>Oversaw and orchestrated the event organisation as the representative of the network team towards the event’s project management, including sponsor aquisation, budget management, and logistic for a highly reliable fault tolerant network for one of the largest hacker events in Germany.&lt;/p>
&lt;p>• Lead a Team of 15 volunteers with various skills and levels to build and run the network infrastructure&lt;/p>
&lt;p>• Planned and controlled the budget&lt;/p>
&lt;p>• Acquired sponsors for network hardware and BGP interconnectivity&lt;/p>
&lt;p>• Wrote a SDN Controller in python3 using netconf, SNMPv3, and jinja2 for a heterogenous infrastructure to distribute the network in 5 lecture halls, two big hackcenters and the “OpenCodes” Art exhibition&lt;/p>
&lt;p>• Created extensive documentation during all stages of the project to ensure a reliable network&lt;/p>
&lt;p>• Worked together with 3rd party service providers to provide fiber connectivity as well as multi-homed BGP connectivity to the venue&lt;/p>
&lt;p>• Monitored the whole network infrastructure using Prometheus and Grafana&lt;/p></description></item><item><title>rC3 World Backend</title><link>/project/rc3/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>/project/rc3/</guid><description>&lt;p>Supported the &lt;a href="https://rc3.world/2021/world">rc3.world&lt;/a> backend team as part of the &lt;a href="https://infra.rc3.world">rC3 infrastructure team&lt;/a>, building and maintaining a Kubernetes Cluster as well as the corresponding multi-staged Elixir deployment required for the remote congress experience.&lt;/p>
&lt;p>• Orchestrated a highly available Elixir Application using Kubernetes with Kustomize, Helm, and ArgoCD&lt;/p>
&lt;p>• Built a multi-staged GitLab CI Pipeline to compile, verify, an Elexir application, as well as the documentation, that powered the 2D world backend to the congress 2D world&lt;/p>
&lt;p>• Coordinated deployments in close collaboration with the leadership team (PL) of the event ensuring minimal disruption during for all users&lt;/p>
&lt;p>• Took 24h on-call responsibility during the whole event to resolve incidents as well as smaller issues&lt;/p></description></item></channel></rss>